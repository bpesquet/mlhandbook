{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a self-correcting activity generated by [nbgrader](https://nbgrader.readthedocs.io). Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household power consumption\n",
    "\n",
    "The goal of this activity is to analyze a time series in order to predict the electric consumption of a home.\n",
    "\n",
    "It uses a [dataset](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption#) gathering measurements for a house located in Sceaux (France) between December 2006 and November 2010.\n",
    "\n",
    "Attribute description is as follows:\n",
    "\n",
    "1. **date**: date in format dd/mm/yyyy\n",
    "2. **time**: time in format hh:mm:ss\n",
    "3. **global_active_power**: household global minute-averaged active power (in kilowatt)\n",
    "4. **global_reactive_power**: household global minute-averaged reactive power (in kilowatt)\n",
    "5. **voltage**: minute-averaged voltage (in volt)\n",
    "6. **global_intensity**: household global minute-averaged current intensity (in ampere)\n",
    "7. **sub_metering_1**: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).\n",
    "8. **sub_metering_2**: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.\n",
    "9. **sub_metering_3**: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.\n",
    "\n",
    "The active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3 is geven par the following formula:\n",
    "\n",
    "```python\n",
    "global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "assert platform.python_version_tuple() >= (\"3\", \"6\")\n",
    "\n",
    "import os  # To access locally extracted file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tf.keras.__version__}\")\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Lambda, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series, y_true, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\"):\n",
    "    \"\"\"Plot a time series with actual and predicted future values\n",
    "    series: vector of shape (time steps, )\n",
    "    y_true: scalar (if only 1 ahead step) or vector of shape (ahead steps,)\n",
    "    y_pred: scalar (if only 1 ahead step) or vector of shape (ahead steps,)\"\"\"\n",
    "\n",
    "    plt.plot(series, \".-\", label=\"Inputs\")\n",
    "    n_steps = series.shape[0]\n",
    "\n",
    "    # Calculate the number of steps ahead (= number of future values)\n",
    "    n_steps_ahead = 1\n",
    "    if not np.isscalar(y_true):\n",
    "        n_steps_ahead = y_true.shape[0]\n",
    "\n",
    "    # Plot actual future values\n",
    "    plt.plot(np.arange(n_steps, n_steps + n_steps_ahead), y_true, \"ro-\", label=\"Labels\")\n",
    "\n",
    "    if y_pred is not None:\n",
    "        # Plot predicted future values\n",
    "        plt.plot(\n",
    "            np.arange(n_steps, n_steps + n_steps_ahead),\n",
    "            y_pred,\n",
    "            \"bx-\",\n",
    "            label=\"Predicted\",\n",
    "            markersize=10,\n",
    "        )\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16)\n",
    "\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    \"\"\"Plot training loss for a Keras model\n",
    "    Takes a Keras History object as parameter\"\"\"\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, loss, \".--\", label=\"Training loss\")\n",
    "    final_loss = loss[-1]\n",
    "    title = \"Training loss: {:.4f}\".format(final_loss)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    if \"val_loss\" in history.history:\n",
    "        val_loss = history.history[\"val_loss\"]\n",
    "        plt.plot(epochs, val_loss, \"o-\", label=\"Validation loss\")\n",
    "        final_val_loss = val_loss[-1]\n",
    "        title += \", Validation loss: {:.4f}\".format(final_val_loss)\n",
    "    plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset\n",
    "zip_path = get_file(\n",
    "    origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\",\n",
    "    fname=\"household_power_consumption.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "file_path, _ = os.path.splitext(zip_path)\n",
    "file_path += \".txt\"\n",
    "print(f\"Dataset extracted at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "# - \"Date\" and \"Time\" columns are merged into a \"Date_time\" attribute, which is used as index column\n",
    "# - Missing values (\"nan\" and \"?\") are converted into NumPy NaNs\n",
    "df_power = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\";\",\n",
    "    parse_dates={\"Date_time\": [\"Date\", \"Time\"]},\n",
    "    infer_datetime_format=True,\n",
    "    low_memory=False,\n",
    "    na_values=[\"?\"],\n",
    "    index_col=\"Date_time\",\n",
    ")\n",
    "print(f\"df_power: {df_power.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: exploring the data\n",
    "\n",
    "Use pandas to gain insights about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72b84dd0309041a0737e06fef3bf33d5",
     "grade": true,
     "grade_id": "cell-d795055cbec71b78",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e744e88964f9f2ae6c84ab423009fdb5",
     "grade": true,
     "grade_id": "cell-56e4be4c0a302743",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "200e5157a681ce2fee64fac50a946e83",
     "grade": true,
     "grade_id": "cell-e050d837806439e3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number and percent of missing values among features\n",
    "def find_missing_values(df):\n",
    "    total_missing = df.isnull().sum()\n",
    "    percent_missing = (total_missing * 100 / df.isnull().count()).sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    "    return pd.concat(\n",
    "        [total_missing, percent_missing], axis=1, keys=[\"Total\", \"Percent\"]\n",
    "    )\n",
    "\n",
    "\n",
    "find_missing_values(df_power).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first samples with missing values\n",
    "df_power[df_power.isnull().any(axis=1)].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean for all features\n",
    "def fill_na(df):\n",
    "    n_features = df.shape[1]\n",
    "    for j in range(0, n_features):\n",
    "        df.iloc[:, j] = df.iloc[:, j].fillna(df.iloc[:, j].mean())\n",
    "    return df\n",
    "\n",
    "\n",
    "df_power = fill_na(df_power)\n",
    "\n",
    "# Check that there are no remaining missing values\n",
    "df_power.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample dataset over hours rather than minutes, to speed up computations\n",
    "df_power = df_power.resample(\"h\").mean()\n",
    "print(f\"df_power: {df_power.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = [\"Global_active_power\", \"Voltage\", \"Global_intensity\"]\n",
    "\n",
    "# Plot several features resampled over hour for the whole dataset\n",
    "df_plotted_cols = df_power[plot_cols]\n",
    "_ = df_plotted_cols.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several features resampled over hour for the first 20 days of the dataset\n",
    "_ = df_plotted_cols[:480].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Split the dataset using (70%, 20%, 10%) ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54636af66a674a7dc143531c39ee2418",
     "grade": true,
     "grade_id": "cell-9212fcc69f737f51",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset between training, validation and test sets\n",
    "# No shuffling to preserve time dependencies\n",
    "n_samples = len(df_power)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_val: {df_val.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Standardize the splitted sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3744f560f046c51845bc967c48851f2f",
     "grade": true,
     "grade_id": "cell-8e2f9e47777d679c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the sets using metrics computed on training set\n",
    "train_mean = df_train.mean()\n",
    "train_std = df_train.std()\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of the features\n",
    "df_std = (df_power - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name=\"Features\", value_name=\"Normalized_values\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x=\"Features\", y=\"Normalized_values\", data=df_std)\n",
    "_ = ax.set_xticklabels(df_power.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into time windows\n",
    "# input_width is the number of input time steps\n",
    "# label_width is the number of predicted time steps\n",
    "def split_into_windows(dataset, input_width, label_width):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = input_width\n",
    "    end_index = len(dataset) - label_width\n",
    "    for i in range(start_index, end_index):\n",
    "        input_indices = range(i - input_width, i)\n",
    "        inputs.append(dataset[input_indices])\n",
    "        label_indices = range(i, i + label_width)\n",
    "        labels.append(dataset[label_indices])\n",
    "\n",
    "    return np.array(inputs), np.array(labels)\n",
    "\n",
    "\n",
    "def plot_features(series, y_true, y_pred=None, title=None):\n",
    "    plot_cols = [0, 2, 3]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(plot_cols), ncols=1, sharey=True, figsize=(12, 8)\n",
    "    )\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=18)\n",
    "    for i, col in enumerate(plot_cols):\n",
    "        plt.sca(axes[i])\n",
    "        plot_series(\n",
    "            series=series[:, col],\n",
    "            y_true=y_true[:, col],\n",
    "            y_pred=y_pred[:, col] if y_pred is not None else None,\n",
    "            x_label=\"$Time (h)$\",\n",
    "            y_label=df_train.columns[col],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Complete the definition of the `train()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f27ee64d0e6f78df1f601ad537b258e",
     "grade": true,
     "grade_id": "cell-a08153ee98c10415",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_val, y_val):\n",
    "    # Train a model using Adam, mean_squared_error for loss and mae for metric\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = df_power.shape[1]\n",
    "\n",
    "# Hyperparameters\n",
    "n_steps_before = 24\n",
    "n_steps_ahead = 5\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_into_windows(df_train.values, n_steps_before, n_steps_ahead)\n",
    "x_val, y_val = split_into_windows(df_val.values, n_steps_before, n_steps_ahead)\n",
    "x_test, y_test = split_into_windows(df_test.values, n_steps_before, n_steps_ahead)\n",
    "\n",
    "print(f\"x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"x_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"x_test: {x_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot last validation series\n",
    "plot_features(x_val[-1], y_val[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate last values for all features\n",
    "y_pred_naive = np.tile(x_val[:, -1:, :], (n_steps_ahead, 1))\n",
    "print(f\"y_pred_naive: {y_pred_naive.shape}\")\n",
    "\n",
    "print(f\"Naïve predictor MSE: {np.mean(mean_squared_error(y_val, y_pred_naive)):0.05f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51f78309206da09bba6d7a9febbb8b5c",
     "grade": true,
     "grade_id": "cell-02a4b3c112858754",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot forecasting for last validation series\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = Sequential(\n",
    "    [\n",
    "        # Take the last time-step.\n",
    "        # Shape [batch, time, features] => [batch, 1, features]\n",
    "        Lambda(lambda x: x[:, -1:, :]),\n",
    "        # Shape => [batch, 1, dense_units]\n",
    "        Dense(units=512, activation=\"relu\"),\n",
    "        # Shape => [batch, n_steps_ahead*n_features]\n",
    "        Dense(\n",
    "            units=n_steps_ahead * n_features, kernel_initializer=tf.initializers.zeros()\n",
    "        ),\n",
    "        # Shape => [batch, n_steps_ahead, n_features]\n",
    "        Reshape([n_steps_ahead, n_features]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(dense_model, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dense = dense_model.predict(x_val)\n",
    "\n",
    "print(f\"Dense network MSE: {np.mean(mean_squared_error(y_val, y_pred_dense)):0.05f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "039d9e0cdb5df9f6376de2d3d8215365",
     "grade": true,
     "grade_id": "cell-f8e033e171ea84e5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot forecasting for last validation series\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent network\n",
    "\n",
    "Using the architecture of your choice, define a recurrent neural network able to beat the dense model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2de6b9aeeafff3abafe4a263e64cb458",
     "grade": true,
     "grade_id": "cell-27d67cf29fca46c5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d408013f0a3b52fb963559dd3035996b",
     "grade": true,
     "grade_id": "cell-3292db449c5f5935",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fbbe007baf62f14a6c9d784fb63e18a",
     "grade": true,
     "grade_id": "cell-3b8186ec3258032e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d57fb77a8f396066273fe101fd742b",
     "grade": true,
     "grade_id": "cell-152384b09e047ca7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27dda887ef77df916ce223926c88bf7",
     "grade": true,
     "grade_id": "cell-8bbb7a9d10acae42",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
