{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a self-correcting activity generated by [nbgrader](https://nbgrader.readthedocs.io). Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast the weather\n",
    "\n",
    "The goal of this activity is to analyze a times series with a Recurrent Neural Network (RNN), in order to forecast the weather based on past observations.\n",
    "\n",
    "It uses a [weather dataset](https://www.bgc-jena.mpg.de/wetter/) recorded from 2003 to 2016 by the [Max Planck Institute for Biogeochemistry](https://www.bgc-jena.mpg.de/) in Jena, Germany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "assert platform.python_version_tuple() >= (\"3\", \"6\")\n",
    "\n",
    "import os  # To access locally extracted file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19c30d295942948fe088dfaf148d7524",
     "grade": true,
     "grade_id": "cell-036aee07eff06548",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tf.keras.__version__}\")\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "# You may add other imports here as needed\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "\n",
    "def plot_series(series, y_true, y_pred=None, x_label=\"$t$\", y_label=\"$temp(t)$\"):\n",
    "    \"\"\"Plot a time series with actual and predicted future values\n",
    "    series: vector of shape (time steps, )\n",
    "    y_true: scalar (if only 1 ahead step) or vector of shape (ahead steps,)\n",
    "    y_pred: scalar (if only 1 ahead step) or vector of shape (ahead steps,)\"\"\"\n",
    "\n",
    "    plt.plot(series, \".-\")\n",
    "    n_steps = series.shape[0]\n",
    "\n",
    "    # Calculate the number of steps ahead (= number of future values)\n",
    "    n_steps_ahead = 1\n",
    "    if not np.isscalar(y_true):\n",
    "        n_steps_ahead = y_true.shape[0]\n",
    "\n",
    "    # Plot actual future values\n",
    "    plt.plot(np.arange(n_steps, n_steps + n_steps_ahead), y_true, \"ro-\", label=\"Actual\")\n",
    "\n",
    "    if y_pred is not None:\n",
    "        # Plot predicted future values\n",
    "        plt.plot(\n",
    "            np.arange(n_steps, n_steps + n_steps_ahead),\n",
    "            y_pred,\n",
    "            \"bx-\",\n",
    "            label=\"Predicted\",\n",
    "            markersize=10,\n",
    "        )\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=90)\n",
    "\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    \"\"\"Plot training loss for a Keras model\n",
    "    Takes a Keras History object as parameter\"\"\"\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, loss, \".--\", label=\"Training loss\")\n",
    "    final_loss = loss[-1]\n",
    "    title = \"Training loss: {:.4f}\".format(final_loss)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    if \"val_loss\" in history.history:\n",
    "        val_loss = history.history[\"val_loss\"]\n",
    "        plt.plot(epochs, val_loss, \"o-\", label=\"Validation loss\")\n",
    "        final_val_loss = val_loss[-1]\n",
    "        title += \", Validation loss: {:.4f}\".format(final_val_loss)\n",
    "    plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset\n",
    "zip_path = get_file(\n",
    "    origin=\"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\",\n",
    "    fname=\"jena_climate_2009_2016.csv.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "print(f\"Dataset extracted at {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df_weather = pd.read_csv(csv_path)\n",
    "print(f\"Dataset: {df_weather.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Show the first 10 data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28889adcd1722bea4c6e3b871f4d6d18",
     "grade": true,
     "grade_id": "cell-c8b5314f2c18ce7d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: preparing the data\n",
    "\n",
    "You'll try to predict the temperature by using only the past temperatures, and not the other features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the temperature feature in the dataset\n",
    "df_univariate = df_weather[\"T (degC)\"]\n",
    "\n",
    "# Add time to ease visualization\n",
    "df_univariate.index = df_weather[\"Date Time\"]\n",
    "\n",
    "df_univariate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temperatures over time\n",
    "df_univariate.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "It is important to scale features before training a neural network. Standardization is a common way of doing this scaling by subtracting the mean and dividing by the standard deviation of each feature.\n",
    "\n",
    "Standardize the data using values computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "007c244637f42519c3721ef7abe2ad5f",
     "grade": true,
     "grade_id": "cell-79497947dab5856f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# First 300,000 samples fo training\n",
    "# Next 60,000 samples for validation\n",
    "# Remaining samples for test\n",
    "TRAIN_SPLIT = 300000\n",
    "VAL_SPLIT = 360000\n",
    "\n",
    "# Compute the mean and standard deviation on training set only\n",
    "x_train_mean = df_univariate[:TRAIN_SPLIT].mean()\n",
    "x_train_std = df_univariate[:TRAIN_SPLIT].std()\n",
    "\n",
    "# Standardize the dataset\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df_univariate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating inputs and targets\n",
    "\n",
    "It's time to split the dataset as usual and create training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "    \"\"\"Create inputs and targets for a window of time defined by start_index and end_index\n",
    "    history_size: number of time steps of the window\n",
    "    target_size: number of steps ahead to be predicted\"\"\"\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i - history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        labels.append(dataset[i + target_size])\n",
    "    return np.array(data), np.array(labels).reshape(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using the 20 last temperature observations to predict the next one.\n",
    "past_history = 20\n",
    "future_target = 0\n",
    "\n",
    "x_train, y_train = prepare_univariate_data(\n",
    "    df_univariate.values, 0, TRAIN_SPLIT, past_history, future_target,\n",
    ")\n",
    "x_val, y_val = prepare_univariate_data(\n",
    "    df_univariate.values, TRAIN_SPLIT, VAL_SPLIT, past_history, future_target,\n",
    ")\n",
    "x_test, y_test = prepare_univariate_data(\n",
    "    df_univariate.values, VAL_SPLIT, None, past_history, future_target,\n",
    ")\n",
    "\n",
    "print(f\"x_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"x_val: {x_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"x_test: {x_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first validation series with ground truth\n",
    "plot_series(series=x_val[0, :, 0], y_true=y_val[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: training models\n",
    "\n",
    "We start by defining a baseline model using a naïve approach, then try to beat it using a RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ca88a2bba935354917ed9abf439d42",
     "grade": false,
     "grade_id": "cell-9cb0cb7537fba085",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Baseline prediction = input for last time step\n",
    "y_pred_baseline = x_val[:, -1]\n",
    "print(f\"y_pred_baseline: {y_pred_baseline.shape}\")\n",
    "\n",
    "baseline_mse = np.mean(mean_squared_error(y_val, y_pred_baseline))\n",
    "\n",
    "# Print MSE\n",
    "print(f\"Baseline MSE: {baseline_mse:0.05f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first validation series with ground truth and prediction\n",
    "plot_series(series=x_val[0, :, 0], y_true=y_val[0, 0], y_pred=y_pred_baseline[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Define a Recurrent Neural Network model able to learn from the prepared data and predict the temperature one step ahead. Store it in the `univariate_model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba59624ec43121e0a93c1c41808ab921",
     "grade": true,
     "grade_id": "cell-c25dac12fd419c47",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "univariate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and traing the model\n",
    "\n",
    "univariate_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "history = univariate_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compute the model's prediction on validation data. Store the result in the `y_pred_univariate` variable.\n",
    "\n",
    "The model's MSE must be lower than the baseline model's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff30398aaa228ca0dcd2b846f11197ac",
     "grade": false,
     "grade_id": "cell-0d821fe09620d07c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27349f82b3c4c1b4f8216e063de68f1b",
     "grade": true,
     "grade_id": "cell-47c5f874c9c101d2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "univariate_mse = np.mean(mean_squared_error(y_val, y_pred_univariate))\n",
    "\n",
    "# Print MSE\n",
    "print(f\"Univariate MSE: {univariate_mse:0.05f}\")\n",
    "\n",
    "assert univariate_mse < baseline_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first validation series with ground truth and prediction\n",
    "plot_series(series=x_val[0, :, 0], y_true=y_val[0, 0], y_pred=y_pred_univariate[0, 0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
