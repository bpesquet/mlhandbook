{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.5\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "assert platform.python_version_tuple() >= (\"3\", \"6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model lifecycle\n",
    "\n",
    "There are two (repeatable) phases:\n",
    "\n",
    "- **Training**: using training input samples, the model learns to find a relationship between features and labels.\n",
    "- **Inference**: the trained model is used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters Vs hyperparameters\n",
    "\n",
    "- $\\pmb{\\theta}$ (sometime noted $\\pmb{\\omega}$): set of model's internal parameters, updated during training.\n",
    "- Many models also have user-defined properties called **hyperparameters**:\n",
    "  - maximum depth of a decision tree;\n",
    "  - number of layers of a neural network;\n",
    "  - ...\n",
    "- Contrary to internal parameters, they are not automatically updated during training.\n",
    "- The hyperparameters directly affect the model's performance and must be tweaked during the tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization algorithm\n",
    "\n",
    "- Used during the training phase.\n",
    "- Objective: find the set of model parameters $\\pmb{\\theta}^{*}$ that minimizes the loss.\n",
    "- For each learning type, several algorithms of various complexity exist.\n",
    "\n",
    "[![Optimization: linear regression](images/LossSideBySide.png)](https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An iterative approach\n",
    "\n",
    "The model's parameters are iteratively updated until an optimum is reached.\n",
    "\n",
    "[![Iterative approach](images/GradientDescentDiagram.png)](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The gradient descent algorithm\n",
    "\n",
    "- Used in several ML models, including neural networks.\n",
    "- General idea: converging to a loss function's minimum by updating model parameters in small steps, in the **opposite direction** of the loss function **gradient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The notion of gradient\n",
    "\n",
    "- Expresses the variation of a function relative to the variation of its parameters.\n",
    "- Vector containing partial derivatives of the function *w.r.t.* each of its $P$ parameters.\n",
    "\n",
    "$$\\nabla_{\\theta}\\mathcal{L}(\\boldsymbol{\\pmb{\\theta}}) = \\begin{pmatrix}\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_1} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_2} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\vdots \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_P} \\mathcal{L}(\\boldsymbol{\\theta})\n",
    "     \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1D gradient descent (one parameter)\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_1parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2D gradient (two parameters)\n",
    "\n",
    "![Tangent Space](images/tangent_space.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2D gradient descent\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_2parameters.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Batch Gradient Descent\n",
    "\n",
    "The gradient is computed on the whole dataset before model parameters are updated.\n",
    "\n",
    "- Advantages: simple and safe (always converges in the right direction).\n",
    "- Drawback: can become slow and even untractable with a big dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The gradient is computed on only one randomly chosen sample whole dataset before parameters are updated.\n",
    "\n",
    "- Advantages:\n",
    "  - Very fast.\n",
    "  - Enables learning from each new sample (*online learning*).\n",
    "- Drawback:\n",
    "  - Convergence is not guaranteed.\n",
    "  - No vectorization of computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Mini-Batch SGD\n",
    "\n",
    "The gradient is computed on a small set of samples, called a *batch*, before parameters are updated.\n",
    "\n",
    "- Combines the advantages of batch and stochastic GD.\n",
    "- Default method for many ML libraries.\n",
    "- The mini-batch size varies between 10 and 1000 samples, depending of the dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Learning rate\n",
    "\n",
    "$\\eta$ is the update factor for parameters once gradient is computed, called the **_learning rate_**.\n",
    "\n",
    "It has a direct impact on the \"speed\" of the gradient descent.\n",
    "\n",
    "$$\\pmb{\\theta_{next}} = \\pmb{\\theta} - \\eta\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Importance of learning rate\n",
    "\n",
    "![Learning rate](images/learning_rate.png)\n",
    "\n",
    "[Interactive exercise](https://developers.google.com/machine-learning/crash-course/fitter/graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The local minima problem\n",
    "\n",
    "![Local minima](images/local_minima.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Gradient Descent](images/gd_ng.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient descent evolution map\n",
    "\n",
    "[![Gradient Descent evolution map](images/gradient_descent_evolution_map.png)](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Momentum\n",
    "\n",
    "Momentum optimization accelerates the descent speed in the direction of the minimum by accumulating previous gradients. It can also escape plateaux faster then plain GD.\n",
    "\n",
    "[![Momemtum demo](images/gd_momentum_demo.gif)](https://youtu.be/qPKKtvkVAjY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Momentum equations\n",
    "\n",
    "$$\\pmb{m_{k+1}} = \\beta_k \\pmb{m_k} - \\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} + \\eta_k\\pmb{m_{k+1}}$$\n",
    "\n",
    "$\\beta_k \\in [0,1]$ is a friction factor that prevents gradients updates from growing too large. A typical value is 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Momentum Vs plain GD\n",
    "\n",
    "[![Momentum Vs plain GD](images/gd_momentum.png)](https://youtu.be/kVU8zTI-Od0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### RMSprop\n",
    "\n",
    "*RMSprop* decays the learning rate differently for each parameter, scaling down the gradient vector along the steepest dimensions. The underlying idea is to adjust the descent direction a bit more towards the global minimum.\n",
    "\n",
    "$$\\pmb{v_{k+1}} = \\beta_k \\pmb{v_k} + (1-\\beta_k) \\left(\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})\\right)^2$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} - \\frac{\\eta_k}{\\sqrt{\\pmb{v_{k}}+\\epsilon}}\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$\\epsilon$ is a smoothing term to avoid divisions by zero. A typical value is $10^{-10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Adam and other techniques\n",
    "\n",
    "*Adam* (*Adaptive Moment Estimation*) combines the ideas of momentum and RMSprop. It is the *de facto* choice nowadays.\n",
    "\n",
    "Gradient descent optimization is a rich subfield of Machine Learning. Read more in [this article](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradients computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numerical differentiation\n",
    "\n",
    "- Finite difference approximation of derivatives.\n",
    "- Generally unstable and limited to a small set of functions.\n",
    "\n",
    "$$\\frac{\\partial f(\\pmb{x})}{\\partial x_i} = \\frac{f(\\pmb{x} + h\\pmb{e}_i) - f(\\pmb{x})}{h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Symbolic differentiation\n",
    "\n",
    "- Automatic manipulation of expressions for obtaining derivative expressions.\n",
    "- Used in modern mathematical software (Mathematica, Maple...).\n",
    "- Can lead to *expression swell*: exponentially large\n",
    "symbolic expressions.\n",
    "\n",
    "$$\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(f(x)+g(x)\\right) = \\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)+\\frac{\\mathrm{d}}{\\mathrm{d}x}g(x)$$\n",
    "\n",
    "$$\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(f(x)g(x)\\right) = \\left(\\frac{\\mathrm{d}}{\\mathrm{d}x}f(x)\\right)g(x)+f(x)\\left(\\frac{\\mathrm{d}}{\\mathrm{d}x}g(x)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Automatic differentiation (*autodiff*)\n",
    "\n",
    "- Family of techniques for efficiently computing derivatives of numeric functions.\n",
    "- Can differentiate closed-form math expressions, but also algorithms using branching, loops or recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autodiff and its main modes\n",
    "\n",
    "- AD combines numerical and symbolic differentiation.\n",
    "- General idea: apply symbolic differentiation at the elementary operation level and keep intermediate numerical results.\n",
    "- AD exists in two modes: forward and reverse. Both rely on the **chain rule**.\n",
    "\n",
    "$$\\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\frac{\\mathrm{d}y}{\\mathrm{d}w_2} \\frac{\\mathrm{d}w_2}{\\mathrm{d}w_1} \\frac{\\mathrm{d}w_1}{\\mathrm{d}x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward mode autodiff\n",
    "\n",
    "- Computes gradients w.r.t. one parameter along with the function output.\n",
    "- Relies on [dual numbers](https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers).\n",
    "- Efficient when output dimension >> number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reverse mode autodiff\n",
    "\n",
    "- Computes function output, then do a backward pass to compute gradients w.r.t. all parameters for the output.\n",
    "- Efficient when number of parameters >> output dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: reverse mode autodiff in action\n",
    "\n",
    "Let's define the function $f$ of two variables $x_1$ and $x_2$ like so:\n",
    "\n",
    "$$f(x_1,x_2) = log_e(x_1) + x_1x_2 - sin(x_2)$$\n",
    "\n",
    "It can be represented as a *computational graph*:\n",
    "\n",
    "![Computational graph](images/computational_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Step 1: forward pass\n",
    "\n",
    "Intermediate values are calculated and tensor operations are memorized for future gradient computations.\n",
    "\n",
    "![The forward pass](images/autodiff_forward_pass.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Step 2: backward pass\n",
    "\n",
    "The [chain rule](https://en.wikipedia.org/wiki/Chain_rule) is applied to compute every intermediate gradient, starting from output.\n",
    "\n",
    "$$y = f(g(x)) \\;\\;\\;\\; \\frac{\\partial y}{\\partial x} = \\frac{\\partial f}{\\partial g} \\frac{\\partial g}{\\partial x}\\;\\;\\;\\; \\frac{\\partial y}{\\partial x} = \\sum_{i=1}^n \\frac{\\partial f}{\\partial g^{(i)}} \\frac{\\partial g^{(i)}}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Autodiff backward pass](images/autodiff_backward_pass.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$y=v_5=v_4-v_3$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial v_4}=1\\;\\;\\;\\;\\frac{\\partial y}{\\partial v_3}=-1$$\n",
    "\n",
    "$$v_4=v_1+v_2$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial v_1}=\\frac{\\partial y}{\\partial v_4}\\frac{\\partial v_4}{\\partial v_1}=1\\;\\;\\;\\;\\frac{\\partial y}{\\partial v_2}=\\frac{\\partial y}{\\partial v_4}\\frac{\\partial v_4}{\\partial v_2}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$v_1 = log_e(x_1)\\;\\;\\;\\;v_2 = x_1x_2\\;\\;\\;\\;v_3 = sin(x_2)$$\n",
    "\n",
    "$$\\frac{\\partial v_1}{\\partial x_1}=\\frac{1}{x_1}\\;\\;\\;\\;\\frac{\\partial v_2}{\\partial x_1}=x_2\\;\\;\\;\\;\\frac{\\partial v_2}{\\partial x_2}=x_1\\;\\;\\;\\;\\frac{\\partial v_3}{\\partial x_2}=cos(x_2)$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x_1}=\\frac{\\partial y}{\\partial v_1}\\frac{\\partial v_1}{\\partial x_1}+\\frac{\\partial y}{\\partial v_2}\\frac{\\partial v_2}{\\partial x_1}=\\frac{1}{x_1}+x_2$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x_2}=\\frac{\\partial y}{\\partial v_2}\\frac{\\partial v_2}{\\partial x_2}+\\frac{\\partial y}{\\partial v_3}\\frac{\\partial v_3}{\\partial x_2}=x_1-cos(x_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autodifferention with PyTorch\n",
    "\n",
    "*Autograd* is the name of PyTorch's autodifferentiation engine.\n",
    "\n",
    "If its `requires_grad` attribute is set to `True`, PyTorch will track all operations on a tensor and provide *reverse mode automatic differentiation*: partial derivatives are automatically computed backward w.r.t. all involved parameters.\n",
    "\n",
    "The gradient for a tensor will be accumulated into its `.grad` attribute.\n",
    "\n",
    "More info on autodiff in PyTorch is available [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: tensor([0.6931], grad_fn=<LogBackward>)\n",
      "v2: tensor([10.], grad_fn=<MulBackward0>)\n",
      "v3: tensor([-0.9589], grad_fn=<SinBackward>)\n",
      "v4: tensor([10.6931], grad_fn=<AddBackward0>)\n",
      "y: tensor([11.6521], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors with autodiff activated\n",
    "# By default, operations are not tracked on user-created tensors\n",
    "x1 = torch.tensor([2.0], requires_grad=True)\n",
    "x2 = torch.tensor([5.0], requires_grad=True)\n",
    "\n",
    "# Compute f() on x1 and x2 step by step\n",
    "v1 = torch.log(x1)\n",
    "v2 = x1 * x2\n",
    "v3 = torch.sin(x2)\n",
    "v4 = v1 + v2\n",
    "y = v4 - v3\n",
    "\n",
    "print(f\"v1: {v1}\")\n",
    "print(f\"v2: {v2}\")\n",
    "print(f\"v3: {v3}\")\n",
    "print(f\"v4: {v4}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000])\n",
      "tensor([1.7163])\n"
     ]
    }
   ],
   "source": [
    "# Let the magic happen\n",
    "y.backward()\n",
    "\n",
    "print(x1.grad) # dy/dx1 = 1/2 + 5 = 5.5\n",
    "print(x2.grad) # dy/dx2 = 2 - cos(5) = 1.7163..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Differentiable programming\n",
    "\n",
    "Aka [software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35).\n",
    "\n",
    "> \"People are now building a new kind of software by assembling networks of parameterized functional blocks and by training them from examples using some form of gradient-based optimization…. It’s really very much like a regular program, except it’s parameterized, automatically differentiated, and trainable/optimizable\" (Y. LeCun).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
